import json
import os
from typing import Set, List, Dict, Any

try:
    from google.cloud import storage as gcs
except ImportError:
    gcs = None

class Storage:
    def __init__(self, file_path: str = "news_state.json"):
        self.file_path = file_path
        self.bucket_name = os.getenv("NEWS_BUCKET_NAME") # å¦‚æœè®¾ç½®äº†æ­¤ç¯å¢ƒå˜é‡ï¼Œåˆ™ä½¿ç”¨ GCS
        self.seen_links: Set[str] = set()
        self.page_hashes: Dict[str, str] = {}
        self.load()

    def load(self):
        """åŠ è½½å·²è¯»æ–‡ç« é“¾æ¥ (ä¼˜å…ˆ GCSï¼Œå…¶æ¬¡æœ¬åœ°)"""
        if self.bucket_name and gcs:
            self._load_from_gcs()
        else:
            self._load_from_local()

    def save(self):
        """ä¿å­˜å½“å‰çŠ¶æ€ (ä¼˜å…ˆ GCSï¼Œå…¶æ¬¡æœ¬åœ°)"""
        if self.bucket_name and gcs:
            self._save_to_gcs()
        else:
            self._save_to_local()

    def _load_from_local(self):
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.seen_links = set(data.get("seen_links", []))
                    self.page_hashes = data.get("page_hashes", {})
                print(f"ğŸ“‚ [Local] Loaded history: {len(self.seen_links)} articles, {len(self.page_hashes)} page hashes.")
            except Exception as e:
                print(f"âš  [Local] Failed to load state: {e}")
                self.seen_links = set()
                self.page_hashes = {}

    def _save_to_local(self):
        try:
            with open(self.file_path, "w", encoding="utf-8") as f:
                json.dump({
                    "seen_links": list(self.seen_links),
                    "page_hashes": self.page_hashes
                }, f, ensure_ascii=False, indent=2)
            # print("ğŸ’¾ [Local] State saved.")
        except Exception as e:
            print(f"âŒ [Local] Failed to save state: {e}")

    def _load_from_gcs(self):
        try:
            client = gcs.Client()
            bucket = client.bucket(self.bucket_name)
            blob = bucket.blob(self.file_path)
            
            if blob.exists():
                data_str = blob.download_as_text()
                data = json.loads(data_str)
                self.seen_links = set(data.get("seen_links", []))
                self.page_hashes = data.get("page_hashes", {})
                print(f"â˜ [GCS] Loaded history from {self.bucket_name}: {len(self.seen_links)} articles.")
            else:
                print(f"â˜ [GCS] No history found in {self.bucket_name}, starting fresh.")
                self.seen_links = set()
                self.page_hashes = {}
        except Exception as e:
            print(f"âš  [GCS] Failed to load state: {e}")
            self.seen_links = set()
            self.page_hashes = {}

    def _save_to_gcs(self):
        try:
            client = gcs.Client()
            bucket = client.bucket(self.bucket_name)
            blob = bucket.blob(self.file_path)
            
            data = json.dumps({
                "seen_links": list(self.seen_links),
                "page_hashes": self.page_hashes
            }, ensure_ascii=False, indent=2)
            
            blob.upload_from_string(data, content_type="application/json")
            print(f"â˜ [GCS] State saved to {self.bucket_name}/{self.file_path}")
        except Exception as e:
            print(f"âŒ [GCS] Failed to save state: {e}")

    def is_new(self, link: str) -> bool:
        """æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºæ–°çš„"""
        return link not in self.seen_links

    def add_seen(self, link: str):
        """æ ‡è®°é“¾æ¥ä¸ºå·²è¯»"""
        self.seen_links.add(link)

    def get_page_hash(self, url: str) -> str:
        """è·å–ä¿å­˜çš„é¡µé¢å“ˆå¸Œå€¼"""
        return self.page_hashes.get(url, "")

    def save_page_hash(self, url: str, content_hash: str):
        """ä¿å­˜é¡µé¢å“ˆå¸Œå€¼"""
        self.page_hashes[url] = content_hash

    def filter_new_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¿‡æ»¤å‡ºæ–°æ–‡ç« """
        new_articles = []
        for art in articles:
            link = art.get('link')
            if link and self.is_new(link):
                new_articles.append(art)
        return new_articles

    def load_favorites(self) -> List[Dict[str, Any]]:
        """åŠ è½½æ”¶è—å¤¹"""
        fav_path = "favorites.json"
        if not os.path.exists(fav_path):
            return []
        try:
            with open(fav_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"âš  Failed to load favorites: {e}")
            return []

    def save_to_favorites(self, article: Dict[str, Any]):
        """ä¿å­˜æ–‡ç« åˆ°æ”¶è—å¤¹ (è‡ªåŠ¨å»é‡)"""
        fav_path = "favorites.json"
        favorites = self.load_favorites()
        
        # Check for duplicate link
        if any(f['link'] == article['link'] for f in favorites):
            print(f"âš  Article already in favorites: {article['title']}")
            return

        favorites.insert(0, article) # Add to top
        try:
            with open(fav_path, "w", encoding="utf-8") as f:
                json.dump(favorites, f, ensure_ascii=False, indent=2)
            print(f"â­ Saved to favorites: {article['title']}")
        except Exception as e:
            print(f"âŒ Failed to save favorite: {e}")
